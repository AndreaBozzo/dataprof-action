name: Test DataProf Action

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  test-csv-single:
    runs-on: ubuntu-latest
    name: Test CSV Single File Analysis

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Create test data
      run: |
        mkdir -p test_data
        cat > test_data/sample.csv << 'EOF'
        id,name,email,age,salary,department,status
        1,Alice Johnson,alice@example.com,28,65000,Engineering,active
        2,Bob Smith,bob@example.com,34,72000,Marketing,active
        3,Carol White,,42,58000,Sales,active
        4,David Brown,david@example.com,31,68000,Engineering,inactive
        5,Emma Davis,emma@example.com,29,63000,Marketing,active
        6,Frank Miller,,38,71000,Sales,active
        7,Grace Wilson,grace@example.com,45,79000,Engineering,active
        8,Henry Moore,henry@example.com,33,66000,Marketing,inactive
        9,Ivy Taylor,ivy@example.com,27,61000,Sales,active
        10,Jack Anderson,jack@example.com,36,74000,Engineering,active
        EOF

    - name: Run DataProf Analysis
      id: dataprof
      uses: ./
      with:
        file: 'test_data/sample.csv'
        quality-threshold: 75
        fail-on-issues: false
        output-format: json

    - name: Display Results
      run: |
        echo "## DataProf Analysis Results"
        echo "Quality Score: ${{ steps.dataprof.outputs.quality-score }}%"
        echo "Quality Level: ${{ steps.dataprof.outputs.quality-level }}"
        echo "Completeness: ${{ steps.dataprof.outputs.completeness-score }}%"
        echo "Uniqueness: ${{ steps.dataprof.outputs.uniqueness-score }}%"
        echo "Validity: ${{ steps.dataprof.outputs.validity-score }}%"
        echo "Consistency: ${{ steps.dataprof.outputs.consistency-score }}%"
        echo "Timeliness: ${{ steps.dataprof.outputs.timeliness-score }}%"
        echo "Accuracy: ${{ steps.dataprof.outputs.accuracy-score }}%"
        echo "Issues Count: ${{ steps.dataprof.outputs.issues-count }}"
        echo "File: ${{ steps.dataprof.outputs.file-path }}"

    - name: Validate Outputs
      run: |
        score="${{ steps.dataprof.outputs.quality-score }}"

        # Check score is numeric
        if ! [[ "$score" =~ ^[0-9]+(\.[0-9]+)?$ ]]; then
          echo "ERROR: Quality score is not numeric: $score"
          exit 1
        fi

        # Check score is in valid range
        if (( $(echo "$score < 0" | bc -l) )) || (( $(echo "$score > 100" | bc -l) )); then
          echo "ERROR: Quality score out of range (0-100): $score"
          exit 1
        fi

        echo "✅ All validations passed!"
        echo "Quality score: ${score}%"

  test-low-quality-data:
    runs-on: ubuntu-latest
    name: Test Low Quality Data Detection

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Create low quality test data
      run: |
        mkdir -p test_data
        cat > test_data/bad_data.csv << 'EOF'
        id,name,email,age,value
        1,Alice,,28,-100
        2,Bob,bob@test,999,50
        3,Carol,,42,75
        4,,,300,25
        5,Emma,emma@test.com,,50
        6,Frank,,38,invalid
        7,Grace,grace@test,45,80
        8,,,33,
        9,Ivy,ivy@test.com,27,90
        10,Jack,,36,100
        EOF

    - name: Run DataProf Analysis (low quality expected)
      id: dataprof-bad
      uses: ./
      with:
        file: 'test_data/bad_data.csv'
        quality-threshold: 50
        fail-on-issues: false
        output-format: json

    - name: Verify Low Quality Detected
      run: |
        score="${{ steps.dataprof-bad.outputs.quality-score }}"
        issues="${{ steps.dataprof-bad.outputs.issues-count }}"

        echo "Quality Score: ${score}%"
        echo "Issues Count: ${issues}"

        # Verify we got valid outputs
        if [[ -z "$score" ]]; then
          echo "❌ No quality score returned"
          exit 1
        fi

        # Low quality data should have issues
        if [[ "$issues" -gt 0 ]]; then
          echo "✅ Quality issues correctly identified: ${issues} issues"
        else
          echo "⚠️  Expected some quality issues in low quality data"
        fi

        echo "✅ Low quality data detection test passed"

  test-json-format:
    runs-on: ubuntu-latest
    name: Test JSON File Analysis

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Create JSON test data
      run: |
        mkdir -p test_data
        cat > test_data/sample.json << 'EOF'
        [
          {"id": 1, "name": "Alice", "email": "alice@test.com", "age": 28, "score": 95},
          {"id": 2, "name": "Bob", "email": "bob@test.com", "age": 34, "score": 87},
          {"id": 3, "name": "Carol", "email": "", "age": 42, "score": 92},
          {"id": 4, "name": "David", "email": "david@test.com", "age": 31, "score": 88},
          {"id": 5, "name": "Emma", "email": "emma@test.com", "age": 29, "score": 91}
        ]
        EOF

    - name: Run DataProf Analysis on JSON
      id: json-test
      uses: ./
      with:
        file: 'test_data/sample.json'
        quality-threshold: 70
        fail-on-issues: false
        output-format: json

    - name: Validate JSON Analysis
      run: |
        score="${{ steps.json-test.outputs.quality-score }}"

        if [[ -z "$score" ]]; then
          echo "❌ No quality score returned for JSON file"
          exit 1
        fi

        echo "✅ JSON file analysis successful"
        echo "Quality score: ${score}%"

  test-json-export:
    runs-on: ubuntu-latest
    name: Test JSON Export Feature

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Create test data
      run: |
        mkdir -p test_data
        cat > test_data/export_test.csv << 'EOF'
        id,value,status
        1,100,active
        2,200,active
        3,150,inactive
        EOF

    - name: Run Analysis with JSON Export
      id: export-test
      uses: ./
      with:
        file: 'test_data/export_test.csv'
        quality-threshold: 70
        export-json-path: 'output/quality_report.json'

    - name: Validate JSON Export
      run: |
        export_path="${{ steps.export-test.outputs.json-export-path }}"

        if [[ -z "$export_path" ]]; then
          echo "❌ No export path returned"
          exit 1
        fi

        if [[ ! -f "$export_path" ]]; then
          echo "❌ Export file not found at: $export_path"
          exit 1
        fi

        # Validate it's valid JSON
        if ! jq empty "$export_path" 2>/dev/null; then
          echo "❌ Exported file is not valid JSON"
          exit 1
        fi

        echo "✅ JSON export successful"
        echo "Export path: $export_path"

  test-batch-mode:
    runs-on: ubuntu-latest
    name: Test Batch Processing Mode

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Create multiple test files
      run: |
        mkdir -p test_data/batch

        # Create multiple CSV files
        cat > test_data/batch/file1.csv << 'EOF'
        id,name,value
        1,Alice,100
        2,Bob,200
        3,Carol,150
        EOF

        cat > test_data/batch/file2.csv << 'EOF'
        id,name,value
        4,David,250
        5,Emma,180
        6,Frank,220
        EOF

        cat > test_data/batch/file3.csv << 'EOF'
        id,name,value
        7,Grace,190
        8,Henry,210
        9,Ivy,175
        EOF

    - name: Run Batch Analysis
      id: batch-test
      uses: ./
      with:
        file: 'test_data/batch/'
        batch-mode: true
        recursive: false
        parallel: true
        quality-threshold: 70
        fail-on-issues: false

    - name: Validate Batch Results
      run: |
        files_analyzed="${{ steps.batch-test.outputs.files-analyzed }}"
        batch_summary="${{ steps.batch-test.outputs.batch-summary }}"

        echo "Files Analyzed: $files_analyzed"
        echo "Batch Summary: $batch_summary"

        # Should have analyzed 3 files
        if [[ "$files_analyzed" -lt 1 ]]; then
          echo "❌ Expected at least 1 file to be analyzed, got: $files_analyzed"
          exit 1
        fi

        if [[ -z "$batch_summary" ]]; then
          echo "❌ No batch summary returned"
          exit 1
        fi

        echo "✅ Batch processing successful"
        echo "Analyzed $files_analyzed file(s)"